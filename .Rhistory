df1_join[,-bad_names]
df1_join[,-c(bad_names)]
subset(df1_join, select = -c(symbol, date, sector, industry))
#-----------------------------------------------------------------------------------------#
#                       Function to build data frame with ratios                          #
#    This functions takes the data that has been cleaned and with that it calculates the  #
#    relevant ratios into a pre-existing dataframe that is  blank dataframe (t_ratio)     #
#    df1 is the blank dataframe, df2 is the dataframe where the data is sourced from      #
f_ratio <- function(df1, df2) {
df1 <<- t_ratio
#Sales
df1$sales <<- df2$revenue
#Asset Turnover
df1$asset_turnover <<- (df2$revenue / df2$total_assets)
#Interest Cover Ratio
df1$interest_cover_ebit_ratio <<- (df2$ebit / df2$interest_expense)
#Cash Flow Cover Ratio
df1$cash_flow_cover_ratio <<- (df2$ebitda / df2$total_current_liabilities)
#Interest Cover (EBITDA) Ratio
df1$interest_cover_ebitda_ratio <<- (df2$ebitda / df2$interest_expense)
#Operating Cash Flow
df1$operating_cash_flow_ratio <<- (df2$operating_cash_flow / df2$total_current_liabilities)
#Debt Ratio
df1$debt_ratio <<- (ifelse(!is.na(df2$short_term_debt & df2$long_term_debt),
df2$short_term_debt + df2$long_term_debt,
ifelse(is.na(df2$short_term_debt) & !is.na(df2$long_term_debt),
df2$long_term_debt,
ifelse(!is.na(df2$short_term_debt) & is.na(df2$long_term_debt),
df2$short_term_debt, NA)))) / (df2$total_assets)
#Total Debt to Equity
df1$total_debt_to_equity_ratio <<- (ifelse(!is.na(df2$short_term_debt & df2$long_term_debt),
df2$short_term_debt + df2$long_term_debt,
ifelse(is.na(df2$short_term_debt) & !is.na(df2$long_term_debt),
df2$long_term_debt,
ifelse(!is.na(df2$short_term_debt) & is.na(df2$long_term_debt),
df2$short_term_debt, NA)))) / (df2$total_shareholders_equity)
#negative ratios and group (special character for if they are missing)
#Long-term debt to equity
df1$long_term_debt_to_equity_ratio <<- (df2$long_term_debt / df2$total_shareholders_equity)
#Cash ratio
df1$cash_ratio <<- (df2$cash_and_cash_equivalents / df2$total_current_liabilities)
#Current Ratio
df1$current_ratio <<- (df2$total_current_assets / df2$total_current_liabilities)
#Net working Capital
df1$net_working_capital <<- (df2$total_current_assets - df2$total_current_liabilities)
#Quick Ratio
df1$quick_ratio <<- ((df2$total_current_assets - df2$inventories) / df2$total_current_liabilities)
#Operating Margin
df1$operating_margin <<- (df2$ebit / df2$revenue)
#ROE
df1$return_on_equity_roe <<- (df2$net_income / df2$total_shareholders_equity)
#Net profit margin
df1$net_profit_margin <<- (df2$net_income / df2$revenue)
#ROA
df1$return_on_assets_roa <<- (df2$net_income / df2$total_assets)
#Gross Profit Margin
df1$gross_profit_margin <<- ((df2$revenue - df2$cost_of_revenue)/ df2$revenue)
#Inventory Turnover
df1$inventory_turnover <<- (df2$revenue / df2$inventories)
#Net Margin Trend
df1$net_margin_trend <<- ((df2$net_income / df2$revenue) - (df2$net_income_last / df2$revenue_last)) / (df2$net_income_last / df2$revenue_last)
#Days Inventory
df1$days_inventory <<- (df2$receivables * 365)/(df2$cost_of_revenue)
#Days Payable
df1$days_payables <<- (df2$payables * 365)/(df2$cost_of_revenue)
#DuPont ROA
df1$du_pont_roa <<- (df2$ebit - df2$income_tax_expense)/df2$total_assets
#DuPont ROE
df1$du_pont_roe <<- ((df2$ebit -(df2$income_tax_expense + df2$interest_expense))/df2$total_shareholders_equity)
#EBIT Trend
df1$ebit_trend <<- ((df2$ebit - df2$ebit_last)/abs(df2$ebit_last))
#EBITDA Trend
df1$ebitda_trend <<- ((df2$ebitda - df2$ebitda_last)/abs(df2$ebitda_last))
#Gross Margin Trend
df1$gross_margin_trend <<- (((df2$ebitda/df2$revenue)-(df2$ebitda_last/df2$revenue_last))/(abs(df2$ebitda_last/df2$revenue_last)))
#Interest Coverage
df1$interest_coverage <<- (df2$operating_cash_flow/df2$interest_expense)
#Pretax Profit Margin
df1$pretax_profit_margin <<- ((df2$ebit + df2$income_tax_expense)/df2$revenue)
#Total Liabilities to Equity Ratio
df1$total_liabilities_to_equity_ratio <<- df2$total_liabilities / df2$total_shareholders_equity
#Return on Average Assets
df1$return_on_average_assets_roaa <<- ((df2$net_income)/((df2$total_assets + df2$total_assets_last)/2))
#Return on Average Equity
df1$return_on_average_equity_roae <<- ((df2$net_income)/((df2$total_shareholders_equity + df2$total_shareholders_equity_last)/2))
#Sales Growth Rate
df1$sales_growth_rate <<- ((df2$revenue - df2$revenue_last)/df2$revenue_last)
#Short Term Financing
df1$short_term_financing <<- (df2$total_current_liabilities/df2$total_assets)
#Average Assets
df1$average_assets <<- ((df2$total_assets_last + df2$total_assets) / 2)
#Average Equity
df1$average_equity <<- ((df2$total_shareholders_equity_last + df2$total_shareholders_equity) / 2)
#Operating Cash Flow
df1$operating_cash_flow <<- df2$operating_cash_flow
#Cash Flow
df1$cash_flow <<- (df2$operating_cash_flow + df2$investing_cash_flow + df2$financing_cash_flow)
#Debt to Capital
df1$debt_to_capital <<- (ifelse(!is.na(df2$short_term_debt & df2$long_term_debt),
df2$short_term_debt + df2$long_term_debt,
ifelse(is.na(df2$short_term_debt) & !is.na(df2$long_term_debt),
df2$long_term_debt,
ifelse(!is.na(df2$short_term_debt) & is.na(df2$long_term_debt),
df2$short_term_debt, NA)))) / (df2$total_shareholders_equity + df2$long_term_debt)
#Liabilities to Assets Ratio
df1$liabilities_to_assets_ratio <<- df2$total_liabilities / df2$total_assets
#Cash to Current Assets
df1$cash_to_current_assets <<- df2$cash_and_cash_equivalents / df2$total_current_assets
#Collection Days
df1$collection_days <<- (df2$receivables * 365) / df2$revenue
#Operating Cash Flow Margin
df1$operating_cash_flow_margin <<- df2$operating_cash_flow /df2$revenue
}
#-----------------------------------------------------------------------------------------#
#                       Function to build relevant statistics                             #
#    This functions takes the data that have been built from the ratios and returns some  #
#    interesting summary statistics about the ratios. This is done between a certain date #
#    range, where year1 is the start year, and year2 is the end year                      #
statistical_overview <- function(year1,year2,data){
t_filtered_ratio <- data %>%
filter(date %in% as.Date(paste(year1,"12-31",sep="-")):as.Date(paste(year2,"12-31",sep="-")))
v_missing <- as.data.frame(diagnose(t_filtered_ratio[3:length(t_filtered_ratio)])[,c(1,3,4)])
v_outlier <- as.data.frame(diagnose_outlier(t_filtered_ratio[3:length(t_filtered_ratio)])[,1:3])
v_summary <- as.data.frame(diagnose_numeric(t_filtered_ratio[3:length(t_filtered_ratio)])[,c(1:7)])
t_statistics <- v_summary %>%
cbind(v_missing[,2:3], v_outlier[2:3])
t_statistics[,"missing_percent"] <- round(t_statistics[,"missing_percent"] /100,digits = 2)
t_statistics[,c(2:7,11)] <- round(t_statistics[,c(2:7,11)],digits = 2)
format(t_statistics, big.mark = ",",scientific = FALSE)
}
#-------------------------------------- Renaming Function -----------------------------------------------------#
#function that changes the column names of the dataset to standardised names located within the mapping document
f_rename_colnames <- function(map, old){
for(i in 1:nrow(map)){
target <- as.character(map[i,1])
for (j in 2:ncol(map)){
bad_name <- as.character(map[i,j])
names(old)[as.character(names(old)) == bad_name] <- target
}
}
# if column names cannot be standardised, because the column name is not present in the data or the mappping is incorrectly named,
# we take the missing user defined variable name and create an empty column for it
UDV <- as.vector(unlist(c(map[,1])))
for (name in 1:length(UDV)){
if(UDV[name] %in% colnames(old)){
print("good")
}else{
data_to_be_added <- data.frame(matrix(nrow = nrow(old), ncol = 1))
colnames(data_to_be_added) <- UDV[name]
old <- cbind(old, data_to_be_added)
}
}
new_df <<- old
}
#-------Function for extracting outliers-------#
outliers <- function(dataframe) {
dataframe %>%
select_if(is.numeric) %>%
map(~ boxplot.stats(.x)$out)
}
###### PSI FUNCTION ######
base_psi <- function(type,variable_select,start_year,group_sector,use){
perc_loaded <- reshaped_df1_join
if (group_sector == "Full") {
perc_loaded  <- perc_loaded
}
else {
perc_loaded  <- perc_loaded  %>%
filter(sector %in% group_sector)
}
perc_loaded <- perc_loaded %>%
filter(Type %in% type)
perc_loaded <- perc_loaded %>%
filter(variable %in% variable_select)
perc_loaded <- perc_loaded%>%
filter(date %in% v_dates[start_year-(year(v_dates[1])-1)])
perc_loaded_sorted <- sort(perc_loaded$value)
perc_loaded_decile <- decile(perc_loaded_sorted)
perc_loaded_decile_df <- data.frame(table(perc_loaded_decile))
decile_year_value <- data.frame(matrix(nrow=1,ncol=9))
for(i in 1:9){
decile_year_value[1,i] <- perc_loaded_sorted[sum(perc_loaded_decile_df[c(1:i),2])] # Finds deciles of year 1
}
colnames(decile_year_value) <- c("perc_.1","perc_.2","perc_.3","perc_.4","perc_.5","perc_.6","perc_.7","perc_.8","perc_.9")
decile_year_value <- decile_year_value
t_full_perc <- reshaped_df1_join
if (group_sector == "Full") {
t_full_perc <- t_full_perc
}
else {
t_full_perc <- t_full_perc %>%
filter(sector %in% group_sector)
}
t_full_perc <- t_full_perc %>%
filter(date %in% c(v_dates[(start_year-(year(v_dates[1])-2)):length(v_dates)]))
t_full_perc <- t_full_perc %>% filter(Type %in% type)
t_full_perc <- t_full_perc %>% filter(variable %in% variable_select)
t_full_perc <- t_full_perc %>%
mutate(perc_exp_.1 = ifelse(value <= decile_year_value[,"perc_.1"],1,0),
perc_exp_.2 = ifelse(value <= decile_year_value[,"perc_.2"],1,0),
perc_exp_.3 = ifelse(value <= decile_year_value[,"perc_.3"],1,0),
perc_exp_.4 = ifelse(value <= decile_year_value[,"perc_.4"],1,0),
perc_exp_.5 = ifelse(value <= decile_year_value[,"perc_.5"],1,0),
perc_exp_.6 = ifelse(value <= decile_year_value[,"perc_.6"],1,0),
perc_exp_.7 = ifelse(value <= decile_year_value[,"perc_.7"],1,0),
perc_exp_.8 = ifelse(value <= decile_year_value[,"perc_.8"],1,0),
perc_exp_.9 = ifelse(value <= decile_year_value[,"perc_.9"],1,0))
t_full_perc <- t_full_perc %>% na.omit()
percentages <- t_full_perc %>%
group_by(date)%>%
summarise_at(vars(perc_exp_.1:perc_exp_.9),mean,na.rm=TRUE)
assign(paste("percentages",sep=""),percentages,envir = globalenv())
deciles <- data.frame(matrix(nrow = (length(v_dates) - (start_year + 1 - year(v_dates[1]))),ncol=10))
deciles[,1] <- percentages[,1]
for(i in 1:9){
deciles[,i+1] <- i/10 - percentages[,i+1]
}
colnames(deciles) <- colnames(percentages)
log_table <- data.frame(matrix(nrow = (length(v_dates) - (start_year + 1 - year(v_dates[1]))),ncol=10))
log_table <- percentages[,1]
for(i in 1:9){
log_table[,i+1] <- log((i/10)/percentages[,i+1],base = exp(1))
}
colnames(log_table) <- colnames(percentages)
psi_single <- log_table[,c(2:10)] * deciles[,c(2:10)]
psi_final <- data.frame(rowSums(psi_single))
psi_dates <- v_dates[(start_year-year(v_dates[1])+2):length(v_dates)]
psi_final <- cbind(psi_dates,psi_final)
psi_final[,2] <- round(psi_final[,2],2)
colnames(psi_final) <- c("date","PSI")
assign(paste("psi_transpose",sep=""),psi_final,envir = globalenv())
if(use == "values"){
return(psi_transpose)
}else{
return(percentages)
}
}
#ROLLING CASE#
#This finds the deciles for the required years that we will use
rolling_psi <- function(type, variable_select, start_year,group_sector,use){
all_deciles <- data.frame()
rolling_data <- data.frame()
deciles_rolling <- data.frame(matrix(nrow = (length(v_dates) - (start_year + 1 - year(v_dates[1]))),ncol=10))
for(i in (start_year-(year(v_dates[1])-1)):length(v_dates)){
variable_data <- reshaped_df1_join
if (group_sector == "Full") {
variable_data <- variable_data
}
else {
variable_data <- variable_data %>%
filter(sector %in% group_sector)
}
variable_data <-variable_data %>%
filter(Type %in% type) %>%
filter(variable %in% variable_select) %>%
filter(date %in% v_dates[i])
sorted_variable <- sort(variable_data$value)
decile_variable <- decile(sorted_variable)
decile_df <- data.frame(table(decile_variable))
decile_year_value <- data.frame(matrix(nrow=1,ncol=9))
for(j in 1:9){
decile_year_value[1,j] <- sorted_variable[sum(decile_df[c(1:j),2])] # Finds deciles of all years
}
colnames(decile_year_value) <- c("perc_.1","perc_.2","perc_.3","perc_.4","perc_.5","perc_.6","perc_.7","perc_.8","perc_.9")
assign(paste("decile",i,sep="_"),  decile_year_value)
}
for(i in (start_year-(year(v_dates[1])-1)):length(v_dates)){
assign(paste("all_deciles",sep=""), rbind(all_deciles, get(paste("decile",i,sep="_"))))
}
all_deciles <<- all_deciles
#We will then look at how we can find the number of how many fit into the previous year
for(i in (start_year-(year(v_dates[1])-1)):(length(v_dates)-1)){
t_full_perc <- reshaped_df1_join
if (group_sector == "Full") {
t_full_perc <- t_full_perc
}
else {
t_full_perc <- t_full_perc %>%
filter(sector %in% group_sector)
}
t_full_perc <- t_full_perc %>%
filter(date %in% c(v_dates[(i+1):(i+1)]))
t_full_perc <- t_full_perc %>% filter(Type %in% type)
t_full_perc <- t_full_perc %>% filter(variable %in% variable_select)
t_full_perc <- t_full_perc %>%
mutate(perc_exp_.1 = ifelse(value <= all_deciles[(i-(start_year - year(v_dates[1]))),"perc_.1"],1,0),
perc_exp_.2 = ifelse(value <= all_deciles[(i-(start_year - year(v_dates[1]))),"perc_.2"],1,0),
perc_exp_.3 = ifelse(value <= all_deciles[(i-(start_year - year(v_dates[1]))),"perc_.3"],1,0),
perc_exp_.4 = ifelse(value <= all_deciles[(i-(start_year - year(v_dates[1]))),"perc_.4"],1,0),
perc_exp_.5 = ifelse(value <= all_deciles[(i-(start_year - year(v_dates[1]))),"perc_.5"],1,0),
perc_exp_.6 = ifelse(value <= all_deciles[(i-(start_year - year(v_dates[1]))),"perc_.6"],1,0),
perc_exp_.7 = ifelse(value <= all_deciles[(i-(start_year - year(v_dates[1]))),"perc_.7"],1,0),
perc_exp_.8 = ifelse(value <= all_deciles[(i-(start_year - year(v_dates[1]))),"perc_.8"],1,0),
perc_exp_.9 = ifelse(value <= all_deciles[(i-(start_year - year(v_dates[1]))),"perc_.9"],1,0))
t_full_perc <-
t_full_perc %>% na.omit()
assign(paste("rolling",i+1,sep="_"),t_full_perc)
}
for(i in (start_year-(year(v_dates[1])-1)):(length(v_dates)-1)){
rolling_data <- rbind(rolling_data,get(paste("rolling",i+1,sep="_")))
}
percentages_rolling <- rolling_data %>%
group_by(date)%>%
summarise_at(vars(perc_exp_.1:perc_exp_.9),mean,na.rm=TRUE)
assign(paste("percentages",sep=""),percentages_rolling,envir = globalenv())
#################GOOD#########################
deciles_rolling[,1] <- percentages_rolling[,1]
for(i in 1:9){
deciles_rolling[,i+1] <- i/10 - percentages_rolling[,i+1]
}
colnames(deciles_rolling) <- colnames(percentages_rolling)
log_table_rolling <- data.frame(matrix(nrow = (length(v_dates) - (start_year + 1 - year(v_dates[1]))),ncol=10))
log_table_rolling <- percentages_rolling[,1]
for(i in 1:9){
log_table_rolling[,i+1] <- log((i/10)/percentages_rolling[,i+1],base = exp(1))
}
colnames(log_table_rolling) <- colnames(percentages_rolling)
psi_single_rolling <- log_table_rolling[,c(2:10)] * deciles_rolling[,c(2:10)]
psi_final_rolling <- data.frame(rowSums(psi_single_rolling))
psi_dates <- v_dates[(start_year-year(v_dates[1])+2):length(v_dates)]
psi_final_rolling <- cbind(psi_dates,psi_final_rolling)
psi_final_rolling[,2] <- round(psi_final_rolling[,2],2)
colnames(psi_final_rolling) <- c("date","PSI")
assign(paste("psi_transpose",sep=""),psi_final_rolling,envir = globalenv())
if(use == "values"){
return(psi_transpose)
}else{
return(percentages)
}
}
#Import the list of equities that were used to import the financial data
equities <- read_excel("//fs02/Users/Bloomberg/financials.xlsx",     ####### FINANCIALS.XLSX ######
sheet = "Equity")
#Import the individual equity financial information
f_financial_info <- function(equity){
financials <- read_excel("//fs02/Users/Bloomberg/financials.xlsx",
sheet = paste0(equity), col_types = c("date",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"),
skip = 5)
financials[1,1] <- as.Date("2004-12-31")
financials$Equity <- paste0(equity)
assign(paste("financials",gsub(" ","_",equity),sep="_"),financials, envir = globalenv())
}
###################################################################################################################
for(i in 1:nrow(equities)){
f_financial_info(equities[i,1])
}
t_financial_data_all <- data.frame()
for(i in 1:nrow(equities)){
t_financial_data_all <- rbind(t_financial_data_all,get(paste("financials",gsub(" ","_",equities[i,1]),sep="_")))
}
# mapping document of all variable names
mapping <- read_excel("//fs02/RAS/Quantitative Risk/dev-tools/modules/financial-tool/analysis/data-definitions.xlsx", sheet = "Mapping")
#run renaming function
f_rename_colnames(mapping, t_financial_data_all)
map_names <- as.vector(unlist(c(mapping[,1])))
not_in <- c()
for(i in 1:length(colnames(new_df))){
if(colnames(new_df)[i] %in% map_names){
}else{
not_in <- c(not_in, colnames(new_df)[i])
}
}
new_df <- new_df %>%
select( - c(not_in))
t_financial_data_all <- new_df
# standardise column names
col_idx <- grep("date", names(t_financial_data_all))
t_financial_data_all <- t_financial_data_all[, c(col_idx, (1:ncol(t_financial_data_all))[-col_idx])]
col_idx <- grep("symbol", names(t_financial_data_all))
t_financial_data_all <- t_financial_data_all[, c(col_idx, (1:ncol(t_financial_data_all))[-col_idx])]
# Remove "US EQUITY" from symbol
t_financial_data_all$symbol <- gsub(" US EQUITY", "", t_financial_data_all$symbol)
# Convert to date format
t_financial_data_all$date <- as.Date(format.Date(t_financial_data_all$date, "%Y-12-31"))
# Replace Zero's with NA values
t_financial_data_all[t_financial_data_all == 0] <- NA
#----------# Import Default Probability Risk Information #----------#
f_rating_info <- function(equity){
rating <- read_excel("//fs02/Users/Bloomberg/default.xlsx",
sheet = paste0(equity),
col_types = c("date", "numeric", "text", "numeric"),
skip = 5)
rating[1,1] <- as.Date("2004-12-31")
rating$Equity <- paste0(equity)
assign(paste("rating",gsub(" ","_",equity),sep="_"),rating, envir = globalenv())
}
for(i in 1:nrow(equities)){
f_rating_info(equities[i,1])
}
t_rating_data_all <- data.frame()
for(i in 1:nrow(equities)){
t_rating_data_all <- rbind(t_rating_data_all,get(paste("rating",gsub(" ","_",equities[i,1]),sep="_")))
}
#cian_test <- c("( ebitda + ebit )")
#
#
#dyl_test <- c(unlist(strsplit(cian_test, " ")))
#
#dyl_test
#
#multiplier_function <- data.frame(matrix(ncol = length(dyl_test), nrow = 7))
#row.names(multiplier_function) <- c("(",")","*","/","+","-","variable")
#
#for(i in 1:length(dyl_test)){
#  if(dyl_test[i] == "("){
#    multiplier_function[1,i] <- 1
#  } else if(dyl_test[i] == ")"){
#    multiplier_function[2,i] <- 1
#  } else if(dyl_test[i] == "*"){
#    multiplier_function[3,i] <- 1
#  } else if(dyl_test[i] == "/"){
#    multiplier_function[4,i] <- 1
#  } else if(dyl_test[i] == "+"){
#    multiplier_function[5,i] <- 1
#  } else if(dyl_test[i] == "-"){
#    multiplier_function[6,i] <- 1
#  } else if(nchar(dyl_test[i]) >= 2){
#    multiplier_function[7,i] <- dyl_test[i]
#  }
#}
#
#all_data_wide[,dyl_test[2]] + all_data_wide[,dyl_test[4]]
#---------------------------------------------------------------------------------------------#
#                               Ratio Definitions                                             #
#   This functions retrieves the list of ratio definitions that have been defined and puts    #
#   them into a table so we can use them in the relevant sections.                            #
t_definitions <- read_excel("//fs02/RAS/Quantitative Risk/dev-tools/modules/financial-tool/analysis/data-definitions.xlsx", sheet = 5)
#---------------------------------------------------------------------------------------------#
#                       Creating a dataframe for our ratios                                   #
#Creating empty data frame using the tickers and the ratio names
v_tickers <- c(as.character(t_financial_data_all$symbol))
v_ratios <- c("symbol", "date", t_definitions$Name)
#----------------------------------------------------------------------------------------#
# relevant to the lag #
#Create a dataframe that includes previous years for each company ############################################################
all_data <- t_financial_data_all
for(i in 1:(nrow(all_data)/15)){
for(j in 3:ncol(all_data)){
outlier_test <- all_data[c((1 + 15*(i-1)):(15 * i)),j]
median_value <- median(as.numeric(unlist(outlier_test)),na.rm = TRUE)
if(is.na(median_value)){
}else{
for(k in 1:15){
if(is.na(outlier_test[k,])){
}else if (outlier_test[k,] > 50 * abs(median_value)){
all_data[(1 + 15*(i-1)+(k-1)),j] <- NA
}else{
all_data[(1 + 15*(i-1)+(k-1)),j] <- all_data[(1 + 15*(i-1)+(k-1)),j]
}
}
}
}
}
last_year <- function(x){lag(x)}
col_names_test <- colnames(t_financial_data_all[,-c(1,2)])
test_change <- all_data %>%
group_by(symbol) %>%
arrange(date,.by_group = TRUE) %>%
mutate_each(funs(last_year),col_names_test)
new_col_names <- paste(colnames(t_financial_data_all),"last",sep="_")
colnames(test_change) <- new_col_names
all_data <- all_data %>%
group_by(symbol) %>%
arrange(date,.by_group = TRUE)
all_data_wide <- cbind(all_data,test_change)
#----------------------------------------------------------------------------------------#
#Creates an empty dataframe that has columns and rows depending on the existing ratios
#that are present and also the tickers are in the main dataframe
# t_ratio is where the ratios go into
t_ratio <- data.frame(matrix(ncol = length(v_ratios), nrow = length(v_tickers)))
colnames(t_ratio) <- v_ratios
t_ratio <- clean_names(t_ratio)
t_ratio$symbol <- all_data_wide$symbol
t_ratio$date <- all_data_wide$date
#Calling ratio function on data
f_ratio(t_ratio, all_data_wide)
names <- colnames(df1)
names <- names[-c(1:2)]
#---------------------------------------------------------------------------------------------#
#             Create a list of the tickers & industries                                       #
tickers <- sort(unique(df1$symbol))
industries <- read_excel("//fs02/RAS/Quantitative Risk/dev-tools/modules/financial-tool/docs/Industries.xlsx")
df1_join <- left_join(df1,industries,by=c("symbol"))
t_rating_data_all$Equity <- gsub(" US EQUITY", "", t_rating_data_all$Equity)
t_rating_data_all$Dates <- as.Date(t_rating_data_all$Dates)
joined_adw <- left_join(df1_join, t_rating_data_all[,c("Dates","BB_1YR_DEFAULT_PROB", "Equity")], by = c("date" = "Dates", "symbol" = "Equity"))
colnames(joined_adw)[48] <- "year_dr"
## Function to melt ratio dataframe
reshape <- function(data1 = df1_join, data2 = t_definitions) {
subset <- subset(data1, select = -c(symbol, date, sector, industry))
names <- colnames(subset)
for(i in 1:length(names)){
data2[i,2] <- names[i]
}
reshaped_df1 <- melt(data1, id.vars = c("symbol", "date", "sector"))
reshaped_df1_final <- left_join(reshaped_df1, data2[, c(1,2)], by = c("variable" = "Name"))
return(reshaped_df1_final)
}
reshape()
setwd("//fs02/RAS/Quantitative Risk/dev-tools/modules/financial-tool")
